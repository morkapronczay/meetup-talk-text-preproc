{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import os\n",
    "from gensim import corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('languages.txt', 'r') as file:\n",
    "    languages = [f.strip('\\n') for f in file.readlines()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CORPUSES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### read common articles in all languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_text(datatype, folder, filename):\n",
    "    with open(os.path.join(datatype, folder, filename), 'r') as file:\n",
    "        return file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = {lan: os.listdir(os.path.join('page_text', lan)) for lan in languages}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, key in enumerate(files.keys()):\n",
    "    if i == 0:\n",
    "        common_files = set(files[key])\n",
    "    else:\n",
    "        common_files = common_files.intersection(set(files[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plain texts\n",
    "texts = {lan: [read_text('page_text', lan, f).lower() \n",
    "               for f in os.listdir(os.path.join('page_text', lan)) if f in common_files] \n",
    "         for lan in languages}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenized text - remove punctuation\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "texts_split = {lan: [tokenizer.tokenize(text) for text in texts[lan]] for lan in languages}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_dicts = {lan: corpora.Dictionary(texts_split[lan]) for lan in languages}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_len(unit, text_dict):\n",
    "    if unit == 'char':\n",
    "        return {key: len(' '.join(value)) for key, value in text_dict.items()}\n",
    "    elif unit == 'word':\n",
    "        ret = {}\n",
    "        for key, value in text_dict.items():\n",
    "            val = []\n",
    "            for f in value:\n",
    "                val += f\n",
    "            print(f\"{key}: {len(val)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en: 708315\n",
      "de: 483394\n",
      "hu: 201883\n",
      "ro: 201783\n"
     ]
    }
   ],
   "source": [
    "get_len('word', texts_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Length in characters:')\n",
    "for key, value in texts_notsplit.items():\n",
    "    print(f\"{key}: {len(' '.join(value))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Length in words:')\n",
    "for key, value in texts.items():\n",
    "    val = []\n",
    "    for f in value:\n",
    "        val += f\n",
    "    print(f\"{key}: {len(val)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Length of unique words:')\n",
    "for key in languages:\n",
    "    print(f\"{key}: {len(text_dicts[key])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "languages_long = {'en': 'english', 'de': 'german', 'hu': 'hungarian', 'ro': 'romanian'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_bylang = {lan: set(stopwords.words(languages_long[lan])) for lan in languages}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_stops = {lan: [[g for g in f if not g in stopwords_bylang[lan]] for f in texts[lan]] for lan in languages}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_stop_dicts = {lan: corpora.Dictionary(texts_stops[lan]) for lan in languages}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Length in words without stops:')\n",
    "for key, value in texts_stops.items():\n",
    "    val = []\n",
    "    for f in value:\n",
    "        val += f\n",
    "    print(f\"{key}: {len(val)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Length of unique words:')\n",
    "for key in languages:\n",
    "    print(f\"{key}: {len(text_stop_dicts[key])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
